{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Cargo las librerias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    " \n",
    "\n",
    "##Cargo las librerias de omdb\n",
    "import omdb\n",
    "import requests\n",
    "\n",
    "##Cargo librerias de scraping web\n",
    "import re \n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "##Para archivos y directorios\n",
    "import io\n",
    "import os\n",
    "import chardet\n",
    "\n",
    "##Librerias de tiempo\n",
    "import time\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "##Libreria del zip\n",
    "from zipfile import ZipFile\n",
    "\n",
    "#Con esto podemos echar un vistazo a código HTML directamente en la Notebook\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "##Librerías utilizadas para el muestreo de género de las peliculas\n",
    "from collections import Counter\n",
    "from random import uniform\n",
    "from random import random\n",
    "from bisect import bisect\n",
    "\n",
    "###Librerias para el conteno de palabras (subtitulos)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk as nl\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import string as st\n",
    "from textblob import TextBlob\n",
    "\n",
    "##Separar training y test\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "##Metricas\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, accuracy_score\n",
    "\n",
    "##Modelos\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "##Graficos\n",
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "##### Trabajo con los subtitulos descargados\n",
    "################################################################################\n",
    "def limpieza(fuente = './Subtitulos/SRT/', purgenewlines = False, lowercase = False):\n",
    "    \"\"\"\n",
    "    Remueve los tiempos y tambien caracteres extranios. \n",
    "    \"\"\"\n",
    "    src = fuente\n",
    "    hora_ini = datetime.now()\n",
    "    \n",
    "    ################# Limpieza #################\n",
    "    timestamp = re.compile('^\\d+\\n?.*\\n?', re.MULTILINE)\n",
    "        #encuentra los numeros de indices y las duraciones\n",
    "    advertise = re.compile ('Advertise your product or brand here\\ncontact\\w?')\n",
    "    brackets = re.compile('\\[[^]]*\\]\\n?|\\([^)]*\\)\\n?|<[^>]*>\\n?|\\{[^}]*\\}\\n?')\n",
    "        #encuentra corchetes y parentesis y lo que puede tener adentro, por ejemplo sonidos\n",
    "    opensubs = re.compile('.*subtitles.*\\n?|.*subs.*\\n?', re.IGNORECASE)\n",
    "        #encuentra las referencias a opensubtitles\n",
    "    urls = re.compile('www.*\\s\\n?|[^\\s]*\\. ?com\\n?')\n",
    "        #encuentra paginas webs\n",
    "    r = re.compile('\\r')\n",
    "        #encuentra returns\n",
    "    puntuaciones = re.compile(\"[^\\w\\s']\")\n",
    "        #encuentra puntuaciones\n",
    "    n = re.compile('\\n')\n",
    "        #encuentra nuevas lineas\n",
    "    \n",
    "    db_sub = pd.DataFrame()\n",
    "    \n",
    "    indice = 0\n",
    "    total_archivos = len(os.listdir(src))\n",
    "    \n",
    "    for filename in os.listdir(src):\n",
    "        try:\n",
    "            if filename[-3:] == \"srt\":\n",
    "\n",
    "                with open(os.path.join(src, filename), 'rb') as f:\n",
    "                    result = chardet.detect(f.read())  # se puede usar readline si el archivo es muy largo\n",
    "\n",
    "                texto = io.open(os.path.join(src, filename), mode=\"r\", encoding=result['encoding'])\n",
    "                texto = texto.read()\n",
    "                \n",
    "                if indice%50 == 0:\n",
    "                    print ('Limpiando', filename)\n",
    "                    print ('Total limpiados', indice+1, 'Faltan', round(((1-(indice+1)/total_archivos)*100),2),'%','\\n')\n",
    "                    print('Tiempo de ejecucion: {}'.format(datetime.now() - hora_ini))\n",
    "                    \n",
    "                texto = timestamp.sub('', texto)\n",
    "                texto = advertise.sub('', texto)\n",
    "                texto = brackets.sub('', texto)\n",
    "                texto = opensubs.sub('', texto)\n",
    "                texto = urls.sub('', texto)\n",
    "                texto = r.sub('', texto)\n",
    "                texto = puntuaciones.sub(' ', texto)\n",
    "                if purgenewlines: \n",
    "                    texto = n.sub(' ', texto)\n",
    "                if lowercase: \n",
    "                    texto = texto.lower()\n",
    "                \n",
    "                salida = {'imdb_id': filename[:-4], 'subtitulo': texto}\n",
    "                salida = pd.DataFrame(salida, index= {indice})\n",
    "                db_sub = pd.concat([db_sub, salida])\n",
    "                indice += 1\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(\"Hubo un error en el id \", filename)\n",
    "            print(e, \"\\n\")\n",
    "            continue\n",
    "    \n",
    "    print (\"LISTO - Limpiados =\", indice+1, '(',round((((indice+1)/total_archivos)*100),2),'%',')')\n",
    "    return db_sub\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Ejecuto la funcion de limpieza de subtitulos\n",
    "db_sub = limpieza()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Guardo el subt\n",
    "db_sub.to_csv('Subtitulos_limpios.csv', sep=';', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
